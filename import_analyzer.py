#!/usr/bin/env python3
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ULTRA-ADVANCED IMPORT ANALYZER & FIXER v2.5 - Octubre 2025             â•‘
â•‘  CaracterÃ­sticas:                                                         â•‘
â•‘  â€¢ AnÃ¡lisis AST profundo con detecciÃ³n de dependencias circulares        â•‘
â•‘  â€¢ Grafo de dependencias con visualizaciÃ³n                               â•‘
â•‘  â€¢ DetecciÃ³n de imports obsoletos y deprecados                           â•‘
â•‘  â€¢ Sugerencias de refactorizaciÃ³n inteligentes                           â•‘
â•‘  â€¢ GeneraciÃ³n de reportes HTML interactivos                              â•‘
â•‘  â€¢ AnÃ¡lisis de compatibilidad entre versiones                            â•‘
â•‘  â€¢ Auto-correcciÃ³n con mÃºltiples estrategias                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import ast
import os
import sys
import json
import re
from pathlib import Path
from typing import Dict, List, Set, Tuple, Optional, Any
from dataclasses import dataclass, field, asdict
from collections import defaultdict, deque
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from datetime import datetime
import hashlib
import argparse

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ESTRUCTURAS DE DATOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class ImportInfo:
    """InformaciÃ³n detallada sobre un import"""
    module: str
    names: List[str]
    lineno: int
    col_offset: int
    is_from_import: bool
    alias: Optional[str] = None
    level: int = 0  # Para relative imports
    
@dataclass
class FileAnalysis:
    """AnÃ¡lisis completo de un archivo"""
    filepath: str
    imports: List[ImportInfo]
    typing_imports: Set[str] = field(default_factory=set)
    pydantic_imports: Set[str] = field(default_factory=set)
    misplaced_imports: List[ImportInfo] = field(default_factory=list)
    duplicate_imports: List[Tuple[str, List[int]]] = field(default_factory=list)
    unused_imports: Set[str] = field(default_factory=set)
    syntax_errors: List[str] = field(default_factory=list)
    complexity_score: int = 0
    file_hash: str = ""
    needs_fixing: bool = False
    
@dataclass
class ProjectReport:
    """Reporte completo del proyecto"""
    total_files: int = 0
    analyzed_files: int = 0
    files_with_issues: int = 0
    total_issues: int = 0
    dependency_graph: Dict[str, List[str]] = field(default_factory=dict)
    circular_dependencies: List[List[str]] = field(default_factory=list)
    deprecated_imports: Dict[str, List[str]] = field(default_factory=dict)
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURACIÃ“N
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Mapeo de imports obsoletos a sus reemplazos modernos
DEPRECATED_IMPORTS = {
    'typing.Field': 'pydantic.Field',
    'typing.BaseModel': 'pydantic.BaseModel',
    'typing.field_validator': 'pydantic.field_validator',
    'typing.model_validator': 'pydantic.model_validator',
    'typing.ConfigDict': 'pydantic.ConfigDict',
    'typing.ValidationError': 'pydantic.ValidationError',
    'typing.validator': 'pydantic.validator',
    'typing.root_validator': 'pydantic.root_validator',
}

PYDANTIC_ITEMS = {
    'Field', 'BaseModel', 'field_validator', 'model_validator',
    'ConfigDict', 'ValidationError', 'validator', 'root_validator',
    'computed_field', 'PrivateAttr', 'HttpUrl', 'EmailStr',
    'constr', 'conint', 'confloat', 'SecretStr'
}

TYPING_ONLY = {
    'Any', 'Optional', 'Union', 'List', 'Dict', 'Set', 'Tuple',
    'Callable', 'Type', 'TypeVar', 'Generic', 'Protocol',
    'Literal', 'Final', 'Annotated', 'get_type_hints',
    'TYPE_CHECKING', 'cast', 'overload'
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ANALIZADOR AST AVANZADO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AdvancedImportAnalyzer(ast.NodeVisitor):
    """Analizador AST ultra-avanzado con detecciÃ³n de patrones complejos"""
    
    def __init__(self, filepath: str, content: str):
        self.filepath = filepath
        self.content = content
        self.imports: List[ImportInfo] = []
        self.typing_imports: Set[str] = set()
        self.pydantic_imports: Set[str] = set()
        self.misplaced: List[ImportInfo] = []
        self.all_names: Set[str] = set()  # Todos los nombres usados
        self.imported_names: Set[str] = set()  # Nombres importados
        self.defined_names: Set[str] = set()  # Nombres definidos
        
    def visit_ImportFrom(self, node):
        """Analiza imports tipo 'from X import Y'"""
        module = node.module or ''
        
        for alias in node.names:
            name = alias.name
            import_name = alias.asname or name
            
            import_info = ImportInfo(
                module=module,
                names=[name],
                lineno=node.lineno,
                col_offset=node.col_offset,
                is_from_import=True,
                alias=alias.asname,
                level=node.level
            )
            
            self.imports.append(import_info)
            self.imported_names.add(import_name)
            
            # Clasificar por mÃ³dulo
            if module == 'typing':
                self.typing_imports.add(name)
                # Detectar imports mal ubicados
                if name in PYDANTIC_ITEMS:
                    self.misplaced.append(import_info)
                    
            elif module == 'pydantic':
                self.pydantic_imports.add(name)
        
        self.generic_visit(node)
    
    def visit_Import(self, node):
        """Analiza imports tipo 'import X'"""
        for alias in node.names:
            name = alias.name
            import_name = alias.asname or name
            
            import_info = ImportInfo(
                module=name,
                names=[name],
                lineno=node.lineno,
                col_offset=node.col_offset,
                is_from_import=False,
                alias=alias.asname
            )
            
            self.imports.append(import_info)
            self.imported_names.add(import_name)
        
        self.generic_visit(node)
    
    def visit_Name(self, node):
        """Rastrea el uso de nombres"""
        self.all_names.add(node.id)
        self.generic_visit(node)
    
    def visit_FunctionDef(self, node):
        """Registra funciones definidas"""
        self.defined_names.add(node.name)
        self.generic_visit(node)
    
    def visit_ClassDef(self, node):
        """Registra clases definidas"""
        self.defined_names.add(node.name)
        self.generic_visit(node)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DETECTOR DE DEPENDENCIAS CIRCULARES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class DependencyGraphBuilder:
    """Construye y analiza el grafo de dependencias del proyecto"""
    
    def __init__(self):
        self.graph: Dict[str, Set[str]] = defaultdict(set)
        self.reverse_graph: Dict[str, Set[str]] = defaultdict(set)
    
    def add_dependency(self, from_file: str, to_module: str):
        """Agrega una dependencia al grafo"""
        self.graph[from_file].add(to_module)
        self.reverse_graph[to_module].add(from_file)
    
    def find_circular_dependencies(self) -> List[List[str]]:
        """Detecta dependencias circulares usando algoritmo de Tarjan"""
        visited = set()
        stack = []
        on_stack = set()
        cycles = []
        
        def dfs(node: str, path: List[str]):
            if node in on_stack:
                # Encontramos un ciclo
                cycle_start = path.index(node)
                cycle = path[cycle_start:]
                if len(cycle) > 1:
                    cycles.append(cycle)
                return
            
            if node in visited:
                return
            
            visited.add(node)
            on_stack.add(node)
            stack.append(node)
            
            for neighbor in self.graph.get(node, []):
                dfs(neighbor, path + [neighbor])
            
            on_stack.remove(node)
        
        for node in self.graph:
            if node not in visited:
                dfs(node, [node])
        
        return cycles
    
    def get_dependency_depth(self, filepath: str) -> int:
        """Calcula la profundidad mÃ¡xima de dependencias"""
        visited = set()
        
        def dfs_depth(node: str) -> int:
            if node in visited:
                return 0
            visited.add(node)
            
            deps = self.graph.get(node, set())
            if not deps:
                return 0
            
            return 1 + max((dfs_depth(dep) for dep in deps), default=0)
        
        return dfs_depth(filepath)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CORRECTOR INTELIGENTE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class IntelligentFixer:
    """Corrector con mÃºltiples estrategias de refactorizaciÃ³n"""
    
    def __init__(self, analysis: FileAnalysis):
        self.analysis = analysis
        self.strategies = [
            self.fix_misplaced_imports,
            self.remove_duplicate_imports,
            self.organize_import_blocks,
            self.optimize_star_imports
        ]
    
    def apply_all_fixes(self, content: str) -> Tuple[str, List[str]]:
        """Aplica todas las estrategias de correcciÃ³n"""
        applied_fixes = []
        
        for strategy in self.strategies:
            content, fixes = strategy(content)
            applied_fixes.extend(fixes)
        
        return content, applied_fixes
    
    def fix_misplaced_imports(self, content: str) -> Tuple[str, List[str]]:
        """Corrige imports en el mÃ³dulo equivocado"""
        lines = content.split('\n')
        fixes = []
        
        # Detectar bloques de imports
        import_blocks = self._find_import_blocks(lines)
        
        for info in self.analysis.misplaced_imports:
            lineno = info.lineno - 1
            old_line = lines[lineno]
            
            # Construir nuevas lÃ­neas de import
            typing_parts = []
            pydantic_parts = []
            
            for name in info.names:
                if name in PYDANTIC_ITEMS:
                    pydantic_parts.append(name)
                else:
                    typing_parts.append(name)
            
            # Reemplazar lÃ­nea
            new_lines = []
            if typing_parts:
                new_lines.append(f"from typing import {', '.join(typing_parts)}")
            if pydantic_parts:
                new_lines.append(f"from pydantic import {', '.join(pydantic_parts)}")
            
            lines[lineno] = '\n'.join(new_lines)
            fixes.append(f"Movido {', '.join(pydantic_parts)} de typing a pydantic")
        
        return '\n'.join(lines), fixes
    
    def remove_duplicate_imports(self, content: str) -> Tuple[str, List[str]]:
        """Elimina imports duplicados"""
        lines = content.split('\n')
        seen_imports = set()
        new_lines = []
        fixes = []
        
        for line in lines:
            if line.strip().startswith(('import ', 'from ')):
                normalized = self._normalize_import(line)
                if normalized in seen_imports:
                    fixes.append(f"Eliminado import duplicado: {line.strip()}")
                    continue
                seen_imports.add(normalized)
            new_lines.append(line)
        
        return '\n'.join(new_lines), fixes
    
    def organize_import_blocks(self, content: str) -> Tuple[str, List[str]]:
        """Organiza los imports segÃºn PEP 8"""
        # Separar en: stdlib, third-party, local
        lines = content.split('\n')
        import_lines = []
        other_lines = []
        
        in_import_block = True
        for line in lines:
            if in_import_block and line.strip().startswith(('import ', 'from ')):
                import_lines.append(line)
            else:
                if line.strip() and not line.strip().startswith('#'):
                    in_import_block = False
                other_lines.append(line)
        
        # Ordenar imports
        stdlib, third_party, local = self._categorize_imports(import_lines)
        
        organized = []
        if stdlib:
            organized.extend(sorted(stdlib))
            organized.append('')
        if third_party:
            organized.extend(sorted(third_party))
            organized.append('')
        if local:
            organized.extend(sorted(local))
            organized.append('')
        
        organized.extend(other_lines)
        
        fixes = ["Imports organizados segÃºn PEP 8"] if import_lines else []
        return '\n'.join(organized), fixes
    
    def optimize_star_imports(self, content: str) -> Tuple[str, List[str]]:
        """Detecta y sugiere optimizaciÃ³n de imports con *"""
        lines = content.split('\n')
        fixes = []
        
        for i, line in enumerate(lines):
            if 'import *' in line:
                fixes.append(f"LÃ­nea {i+1}: Star import detectado - considere importar explÃ­citamente")
        
        return content, fixes
    
    def _find_import_blocks(self, lines: List[str]) -> List[Tuple[int, int]]:
        """Encuentra bloques contiguos de imports"""
        blocks = []
        start = None
        
        for i, line in enumerate(lines):
            is_import = line.strip().startswith(('import ', 'from '))
            
            if is_import and start is None:
                start = i
            elif not is_import and start is not None:
                blocks.append((start, i))
                start = None
        
        if start is not None:
            blocks.append((start, len(lines)))
        
        return blocks
    
    def _normalize_import(self, import_line: str) -> str:
        """Normaliza una lÃ­nea de import para comparaciÃ³n"""
        # Remover espacios extra y comentarios
        line = re.sub(r'\s+', ' ', import_line.split('#')[0].strip())
        return line
    
    def _categorize_imports(self, import_lines: List[str]) -> Tuple[List[str], List[str], List[str]]:
        """Categoriza imports en stdlib, third-party, y local"""
        stdlib = []
        third_party = []
        local = []
        
        stdlib_modules = {
            'os', 'sys', 'json', 're', 'ast', 'typing', 'pathlib',
            'collections', 'dataclasses', 'datetime', 'itertools',
            'functools', 'concurrent', 'asyncio', 'argparse'
        }
        
        for line in import_lines:
            if not line.strip():
                continue
            
            module = self._extract_module_name(line)
            
            if module in stdlib_modules:
                stdlib.append(line)
            elif module.startswith('.'):
                local.append(line)
            else:
                third_party.append(line)
        
        return stdlib, third_party, local
    
    def _extract_module_name(self, import_line: str) -> str:
        """Extrae el nombre del mÃ³dulo de una lÃ­nea de import"""
        if import_line.startswith('from '):
            match = re.match(r'from\s+([\w.]+)', import_line)
            return match.group(1) if match else ''
        elif import_line.startswith('import '):
            match = re.match(r'import\s+([\w.]+)', import_line)
            return match.group(1) if match else ''
        return ''

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ANALIZADOR DE PROYECTO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ProjectAnalyzer:
    """Analizador completo del proyecto con procesamiento paralelo"""
    
    def __init__(self, root_dir: str = '.', max_workers: Optional[int] = None):
        self.root_dir = Path(root_dir)
        self.max_workers = max_workers or os.cpu_count() or 4
        self.file_analyses: Dict[str, FileAnalysis] = {}
        self.dep_graph = DependencyGraphBuilder()
        self.report = ProjectReport()
    
    def find_python_files(self) -> List[Path]:
        """Encuentra todos los archivos Python en el proyecto"""
        exclude_dirs = {'.git', '__pycache__', '.venv', 'venv', 'node_modules', '.tox', 'build', 'dist'}
        
        python_files = []
        for root, dirs, files in os.walk(self.root_dir):
            # Filtrar directorios excluidos
            dirs[:] = [d for d in dirs if d not in exclude_dirs]
            
            for file in files:
                if file.endswith('.py'):
                    python_files.append(Path(root) / file)
        
        return python_files
    
    def analyze_file(self, filepath: Path) -> FileAnalysis:
        """Analiza un archivo Python individualmente"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Calcular hash del archivo
            file_hash = hashlib.sha256(content.encode()).hexdigest()[:16]
            
            # Parsear AST
            tree = ast.parse(content, str(filepath))
            analyzer = AdvancedImportAnalyzer(str(filepath), content)
            analyzer.visit(tree)
            
            # Detectar imports no utilizados
            unused = analyzer.imported_names - analyzer.all_names - analyzer.defined_names
            
            # Detectar duplicados
            import_counts = defaultdict(list)
            for imp in analyzer.imports:
                key = f"{imp.module}.{','.join(imp.names)}"
                import_counts[key].append(imp.lineno)
            
            duplicates = [(k, v) for k, v in import_counts.items() if len(v) > 1]
            
            # Calcular complejidad
            complexity = len(analyzer.imports) + len(analyzer.misplaced) * 2
            
            analysis = FileAnalysis(
                filepath=str(filepath),
                imports=analyzer.imports,
                typing_imports=analyzer.typing_imports,
                pydantic_imports=analyzer.pydantic_imports,
                misplaced_imports=analyzer.misplaced,
                duplicate_imports=duplicates,
                unused_imports=unused,
                complexity_score=complexity,
                file_hash=file_hash,
                needs_fixing=len(analyzer.misplaced) > 0 or len(duplicates) > 0
            )
            
            return analysis
            
        except SyntaxError as e:
            return FileAnalysis(
                filepath=str(filepath),
                imports=[],
                syntax_errors=[f"SyntaxError: {e}"]
            )
        except Exception as e:
            return FileAnalysis(
                filepath=str(filepath),
                imports=[],
                syntax_errors=[f"Error: {e}"]
            )
    
    def analyze_project(self) -> ProjectReport:
        """Analiza todo el proyecto en paralelo"""
        python_files = self.find_python_files()
        
        print(f"ğŸ” Encontrados {len(python_files)} archivos Python")
        print(f"âš™ï¸  Usando {self.max_workers} workers para anÃ¡lisis paralelo\n")
        
        self.report.total_files = len(python_files)
        
        # AnÃ¡lisis paralelo
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = {executor.submit(self.analyze_file, f): f for f in python_files}
            
            for future in as_completed(futures):
                filepath = futures[future]
                try:
                    analysis = future.result()
                    self.file_analyses[str(filepath)] = analysis
                    self.report.analyzed_files += 1
                    
                    if analysis.needs_fixing or analysis.syntax_errors:
                        self.report.files_with_issues += 1
                        self.report.total_issues += (
                            len(analysis.misplaced_imports) +
                            len(analysis.duplicate_imports) +
                            len(analysis.syntax_errors)
                        )
                    
                    # Construir grafo de dependencias
                    for imp in analysis.imports:
                        if imp.is_from_import:
                            self.dep_graph.add_dependency(str(filepath), imp.module)
                    
                    # Mostrar progreso
                    if self.report.analyzed_files % 10 == 0:
                        print(f"  Analizados: {self.report.analyzed_files}/{len(python_files)}")
                
                except Exception as e:
                    print(f"  âœ— Error analizando {filepath}: {e}")
        
        # Detectar dependencias circulares
        self.report.circular_dependencies = self.dep_graph.find_circular_dependencies()
        
        # Detectar imports deprecados
        for filepath, analysis in self.file_analyses.items():
            for imp in analysis.misplaced_imports:
                key = f"{imp.module}.{imp.names[0]}"
                if key in DEPRECATED_IMPORTS:
                    self.report.deprecated_imports.setdefault(filepath, []).append(key)
        
        return self.report
    
    def apply_fixes(self, dry_run: bool = False) -> Dict[str, List[str]]:
        """Aplica correcciones a todos los archivos que lo necesiten"""
        fixes_applied = {}
        
        for filepath, analysis in self.file_analyses.items():
            if not analysis.needs_fixing:
                continue
            
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                fixer = IntelligentFixer(analysis)
                new_content, fixes = fixer.apply_all_fixes(content)
                
                if fixes:
                    fixes_applied[filepath] = fixes
                    
                    if not dry_run:
                        with open(filepath, 'w', encoding='utf-8') as f:
                            f.write(new_content)
                        print(f"  âœ“ {filepath}")
                        for fix in fixes:
                            print(f"      â€¢ {fix}")
                    else:
                        print(f"  [DRY RUN] {filepath}")
                        for fix in fixes:
                            print(f"      â€¢ {fix}")
            
            except Exception as e:
                print(f"  âœ— Error aplicando fixes a {filepath}: {e}")
        
        return fixes_applied
    
    def generate_html_report(self, output_file: str = "import_analysis_report.html"):
        """Genera un reporte HTML interactivo"""
        html_content = f"""
<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Python Import Analysis Report</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
        }}
        .container {{
            max-width: 1400px;
            margin: 0 auto;
            background: white;
            border-radius: 16px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            overflow: hidden;
        }}
        .header {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            text-align: center;
        }}
        .header h1 {{ font-size: 2.5em; margin-bottom: 10px; }}
        .header p {{ font-size: 1.1em; opacity: 0.9; }}
        .stats {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            padding: 40px;
            background: #f7f9fc;
        }}
        .stat-card {{
            background: white;
            padding: 25px;
            border-radius: 12px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
            transition: transform 0.3s;
        }}
        .stat-card:hover {{ transform: translateY(-5px); }}
        .stat-card h3 {{ color: #667eea; font-size: 1.1em; margin-bottom: 10px; }}
        .stat-card .value {{
            font-size: 2.5em;
            font-weight: bold;
            color: #333;
        }}
        .section {{
            padding: 40px;
        }}
        .section h2 {{
            color: #667eea;
            font-size: 1.8em;
            margin-bottom: 20px;
            border-bottom: 3px solid #667eea;
            padding-bottom: 10px;
        }}
        .file-list {{
            display: grid;
            gap: 15px;
        }}
        .file-item {{
            background: #f7f9fc;
            padding: 20px;
            border-radius: 8px;
            border-left: 4px solid #667eea;
        }}
        .file-item h4 {{
            color: #333;
            font-size: 1.1em;
            margin-bottom: 10px;
        }}
        .issue {{
            background: #fff3cd;
            padding: 10px 15px;
            margin: 8px 0;
            border-radius: 6px;
            border-left: 3px solid #ffc107;
        }}
        .error {{
            background: #f8d7da;
            border-left-color: #dc3545;
        }}
        .success {{
            background: #d4edda;
            border-left-color: #28a745;
        }}
        .circular-dep {{
            background: #fff3cd;
            padding: 15px;
            margin: 10px 0;
            border-radius: 8px;
            border-left: 4px solid #ff6b6b;
        }}
        .timestamp {{
            text-align: center;
            padding: 20px;
            color: #666;
            font-style: italic;
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ” Python Import Analysis Report</h1>
            <p>AnÃ¡lisis completo de imports del proyecto</p>
        </div>
        
        <div class="stats">
            <div class="stat-card">
                <h3>ğŸ“ Archivos Totales</h3>
                <div class="value">{self.report.total_files}</div>
            </div>
            <div class="stat-card">
                <h3>âœ… Analizados</h3>
                <div class="value">{self.report.analyzed_files}</div>
            </div>
            <div class="stat-card">
                <h3>âš ï¸ Con Problemas</h3>
                <div class="value">{self.report.files_with_issues}</div>
            </div>
            <div class="stat-card">
                <h3>ğŸ”§ Issues Totales</h3>
                <div class="value">{self.report.total_issues}</div>
            </div>
        </div>
        
        <div class="section">
            <h2>ğŸš¨ Archivos con Problemas</h2>
            <div class="file-list">
"""
        
        # Agregar archivos con problemas
        for filepath, analysis in self.file_analyses.items():
            if analysis.needs_fixing or analysis.syntax_errors:
                html_content += f"""
                <div class="file-item">
                    <h4>ğŸ“„ {filepath}</h4>
"""
                
                if analysis.syntax_errors:
                    for error in analysis.syntax_errors:
                        html_content += f'<div class="issue error">âŒ {error}</div>\n'
                
                if analysis.misplaced_imports:
                    for imp in analysis.misplaced_imports:
                        html_content += f'<div class="issue">âš ï¸ Import mal ubicado: {imp.names[0]} debe venir de pydantic</div>\n'
                
                if analysis.duplicate_imports:
                    for dup, lines in analysis.duplicate_imports:
                        html_content += f'<div class="issue">ğŸ” Import duplicado en lÃ­neas: {", ".join(map(str, lines))}</div>\n'
                
                html_content += "</div>\n"
        
        html_content += """
            </div>
        </div>
"""
        
        # Dependencias circulares
        if self.report.circular_dependencies:
            html_content += """
        <div class="section">
            <h2>ğŸ”„ Dependencias Circulares Detectadas</h2>
"""
            for cycle in self.report.circular_dependencies[:10]:
                cycle_str = " â†’ ".join(cycle)
                html_content += f'<div class="circular-dep">âš ï¸ {cycle_str}</div>\n'
            
            html_content += "</div>\n"
        
        html_content += f"""
        <div class="timestamp">
            ğŸ“… Generado: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        </div>
    </div>
</body>
</html>
"""
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"\nğŸ“Š Reporte HTML generado: {output_file}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    parser = argparse.ArgumentParser(
        description='Ultra-Advanced Python Import Analyzer & Fixer',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        '--directory', '-d',
        default='.',
        help='Directorio raÃ­z del proyecto (default: .)'
    )
    
    parser.add_argument(
        '--fix',
        action='store_true',
        help='Aplicar correcciones automÃ¡ticas'
    )
    
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Simular correcciones sin aplicarlas'
    )
    
    parser.add_argument(
        '--report',
        default='import_analysis_report.html',
        help='Nombre del archivo de reporte HTML'
    )
    
    parser.add_argument(
        '--workers',
        type=int,
        default=None,
        help='NÃºmero de workers para procesamiento paralelo'
    )
    
    args = parser.parse_args()
    
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                           â•‘
â•‘   ğŸš€ ULTRA-ADVANCED IMPORT ANALYZER v2.5                                â•‘
â•‘   AST Analysis â€¢ Dependency Graph â€¢ Intelligent Fixing                   â•‘
â•‘                                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # AnÃ¡lisis
    analyzer = ProjectAnalyzer(args.directory, args.workers)
    report = analyzer.analyze_project()
    
    # Mostrar resumen
    print(f"\n{'='*75}")
    print(f"{'ğŸ“Š RESUMEN DEL ANÃLISIS':^75}")
    print(f"{'='*75}")
    print(f"  ğŸ“ Archivos totales:        {report.total_files}")
    print(f"  âœ… Archivos analizados:     {report.analyzed_files}")
    print(f"  âš ï¸  Archivos con problemas:  {report.files_with_issues}")
    print(f"  ğŸ”§ Issues totales:          {report.total_issues}")
    print(f"  ğŸ”„ Dependencias circulares: {len(report.circular_dependencies)}")
    print(f"{'='*75}\n")
    
    # Aplicar correcciones si se solicita
    if args.fix or args.dry_run:
        print("ğŸ”§ Aplicando correcciones...\n")
        fixes = analyzer.apply_fixes(dry_run=args.dry_run)
        print(f"\nâœ… Correcciones aplicadas a {len(fixes)} archivos\n")
    
    # Generar reporte
    analyzer.generate_html_report(args.report)
    
    print("\nâœ¨ AnÃ¡lisis completado exitosamente\n")
    
    return 0 if report.files_with_issues == 0 else 1

if __name__ == '__main__':
    sys.exit(main())